# Evaluation

With the *evaluation.py* script you can compare two sets of data - predicted segmentation and ground truth, calculate total *Intersection over Union* and *Dice* scores, as well as samlple wise reports. The folders are specified directly in the script, and names of samples should match to correctly identify corresponding pairs. 
Here are are placed *Excel* files with the scores for the 2D model, 2.5D(stacked) model and *nnUnet*, trained on the same amount of data (18 images that where available in the middle of the project - the same images are packed as demo data for downloading).


